{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05e7cc7f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Lumora : Multi-Label Classifier and Smart Search Feature for Contemporary Arts Craft of Filipinos\n",
    "\n",
    "---\n",
    "# Background of the Study\n",
    "\n",
    "\n",
    "## Source of Data\n",
    "to be continue...\n",
    "\n",
    "\n",
    "## Brief Description of Dataset\n",
    "This dataset is designed to train a model for the platform Lumora, which aims to support Filipino artisans. It is a table of product listings, with each row representing a unique handcrafted item.\n",
    "\n",
    "\n",
    "## Model Variables\n",
    "to be continue...\n",
    "\n",
    "\n",
    "## Objectives\n",
    "The objective is to develop a multi-label NLP classifier to automatically assign relevant categories and stylistic attributes to new product listings on the Lumora C2C e-commerce platform. The model will improve product discoverability by generating tags (e.g., cute, crochet, pastel, minimalist) that allow the Smart Search feature to find items even with varied or imperfect user queries.\n",
    "\n",
    "---\n",
    "\n",
    "# Data Collection / Loading\n",
    "description..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "827dd52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product name</th>\n",
       "      <th>Product description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Category</th>\n",
       "      <th>Subcategory</th>\n",
       "      <th>Color</th>\n",
       "      <th>Size</th>\n",
       "      <th>Material</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Product link</th>\n",
       "      <th>Image link</th>\n",
       "      <th>Brand / seller name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flowers Convertible Puso Wedding Tote</td>\n",
       "      <td>A versatile hobo-style tote embroidered with f...</td>\n",
       "      <td>PHP 11172.22</td>\n",
       "      <td>Bags</td>\n",
       "      <td>Wedding Tote</td>\n",
       "      <td>White</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Upcycled fabric, leather</td>\n",
       "      <td>wedding, tote, floral embroidery, Filipino, su...</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>SintaWeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manila Jeepney 3-in-1 Handbag</td>\n",
       "      <td>A colorful handbag inspired by the iconic jeep...</td>\n",
       "      <td>PHP 12406.79</td>\n",
       "      <td>Bags</td>\n",
       "      <td>Handbag</td>\n",
       "      <td>Multicolor</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Upcycled fabric, leather</td>\n",
       "      <td>jeepney, handbag, Filipino, sustainable</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>SintaWeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vinia Hardin Fanny Pack</td>\n",
       "      <td>A belt-style fanny pack handwoven with upcycle...</td>\n",
       "      <td>PHP 4875.93</td>\n",
       "      <td>Bags</td>\n",
       "      <td>Fanny Pack</td>\n",
       "      <td>Black</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Upcycled fabric, leather</td>\n",
       "      <td>fanny pack, Filipino, sustainable</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>SintaWeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sling Bag (Pinilian/Inabel Weave)</td>\n",
       "      <td>A crossbody sling bag showcasing traditional P...</td>\n",
       "      <td>PHP 5554.94</td>\n",
       "      <td>Bags</td>\n",
       "      <td>Sling Bag</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Upcycled fabric, Pinilian/Inabel weave</td>\n",
       "      <td>sling bag, Filipino, handwoven, sustainable</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>SintaWeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alon Woven Waves Shoulder Bag</td>\n",
       "      <td>A shoulder bag with wave-pattern weaving, comb...</td>\n",
       "      <td>PHP 12653.70</td>\n",
       "      <td>Bags</td>\n",
       "      <td>Shoulder Bag</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Upcycled fabric, leather</td>\n",
       "      <td>shoulder bag, woven waves, Filipino, sustainable</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>SintaWeddings</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Product name  \\\n",
       "0  Flowers Convertible Puso Wedding Tote   \n",
       "1          Manila Jeepney 3-in-1 Handbag   \n",
       "2                Vinia Hardin Fanny Pack   \n",
       "3      Sling Bag (Pinilian/Inabel Weave)   \n",
       "4          Alon Woven Waves Shoulder Bag   \n",
       "\n",
       "                                 Product description         Price Category  \\\n",
       "0  A versatile hobo-style tote embroidered with f...  PHP 11172.22     Bags   \n",
       "1  A colorful handbag inspired by the iconic jeep...  PHP 12406.79     Bags   \n",
       "2  A belt-style fanny pack handwoven with upcycle...   PHP 4875.93     Bags   \n",
       "3  A crossbody sling bag showcasing traditional P...   PHP 5554.94     Bags   \n",
       "4  A shoulder bag with wave-pattern weaving, comb...  PHP 12653.70     Bags   \n",
       "\n",
       "    Subcategory       Color         Size  \\\n",
       "0  Wedding Tote       White  Unspecified   \n",
       "1       Handbag  Multicolor  Unspecified   \n",
       "2    Fanny Pack       Black  Unspecified   \n",
       "3     Sling Bag        Blue  Unspecified   \n",
       "4  Shoulder Bag        Blue  Unspecified   \n",
       "\n",
       "                                 Material  \\\n",
       "0                Upcycled fabric, leather   \n",
       "1                Upcycled fabric, leather   \n",
       "2                Upcycled fabric, leather   \n",
       "3  Upcycled fabric, Pinilian/Inabel weave   \n",
       "4                Upcycled fabric, leather   \n",
       "\n",
       "                                                Tags Product link  \\\n",
       "0  wedding, tote, floral embroidery, Filipino, su...  Unspecified   \n",
       "1            jeepney, handbag, Filipino, sustainable  Unspecified   \n",
       "2                  fanny pack, Filipino, sustainable  Unspecified   \n",
       "3        sling bag, Filipino, handwoven, sustainable  Unspecified   \n",
       "4   shoulder bag, woven waves, Filipino, sustainable  Unspecified   \n",
       "\n",
       "    Image link Brand / seller name  \n",
       "0  Unspecified       SintaWeddings  \n",
       "1  Unspecified       SintaWeddings  \n",
       "2  Unspecified       SintaWeddings  \n",
       "3  Unspecified       SintaWeddings  \n",
       "4  Unspecified       SintaWeddings  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "# initializing dataframe\n",
    "df = pd.read_csv('LumoraProductDataset_refactored.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27480ee6",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Information and Summary Statistics\n",
    "description..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1d4d600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 644 entries, 0 to 643\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Product name         644 non-null    object\n",
      " 1   Product description  644 non-null    object\n",
      " 2   Price                644 non-null    object\n",
      " 3   Category             644 non-null    object\n",
      " 4   Subcategory          644 non-null    object\n",
      " 5   Color                644 non-null    object\n",
      " 6   Size                 644 non-null    object\n",
      " 7   Material             644 non-null    object\n",
      " 8   Tags                 644 non-null    object\n",
      " 9   Product link         644 non-null    object\n",
      " 10  Image link           644 non-null    object\n",
      " 11  Brand / seller name  639 non-null    object\n",
      "dtypes: object(12)\n",
      "memory usage: 60.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "399f384a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product name</th>\n",
       "      <th>Product description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Category</th>\n",
       "      <th>Subcategory</th>\n",
       "      <th>Color</th>\n",
       "      <th>Size</th>\n",
       "      <th>Material</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Product link</th>\n",
       "      <th>Image link</th>\n",
       "      <th>Brand / seller name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>644</td>\n",
       "      <td>644</td>\n",
       "      <td>644</td>\n",
       "      <td>644</td>\n",
       "      <td>644</td>\n",
       "      <td>644</td>\n",
       "      <td>644</td>\n",
       "      <td>644</td>\n",
       "      <td>644</td>\n",
       "      <td>644</td>\n",
       "      <td>644</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>601</td>\n",
       "      <td>560</td>\n",
       "      <td>120</td>\n",
       "      <td>46</td>\n",
       "      <td>150</td>\n",
       "      <td>71</td>\n",
       "      <td>68</td>\n",
       "      <td>102</td>\n",
       "      <td>565</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Filipino Capiz Parol Wooden Christmas Ornament</td>\n",
       "      <td>Downloadable graphic design, shirt design, mad...</td>\n",
       "      <td>PHP 1604.94</td>\n",
       "      <td>Jewelry</td>\n",
       "      <td>Ring</td>\n",
       "      <td>Multicolor</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Brass</td>\n",
       "      <td>Filipino Christmas lantern, parol, capiz shell</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>PrettyfulShop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>62</td>\n",
       "      <td>151</td>\n",
       "      <td>59</td>\n",
       "      <td>189</td>\n",
       "      <td>362</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>510</td>\n",
       "      <td>505</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Product name  \\\n",
       "count                                              644   \n",
       "unique                                             601   \n",
       "top     Filipino Capiz Parol Wooden Christmas Ornament   \n",
       "freq                                                 7   \n",
       "\n",
       "                                      Product description        Price  \\\n",
       "count                                                 644          644   \n",
       "unique                                                560          120   \n",
       "top     Downloadable graphic design, shirt design, mad...  PHP 1604.94   \n",
       "freq                                                   11           62   \n",
       "\n",
       "       Category Subcategory       Color      Size Material  \\\n",
       "count       644         644         644       644      644   \n",
       "unique       46         150          71        68      102   \n",
       "top     Jewelry        Ring  Multicolor  Standard    Brass   \n",
       "freq        151          59         189       362       64   \n",
       "\n",
       "                                                  Tags Product link  \\\n",
       "count                                              644          644   \n",
       "unique                                             565            4   \n",
       "top     Filipino Christmas lantern, parol, capiz shell  Unspecified   \n",
       "freq                                                10          510   \n",
       "\n",
       "         Image link Brand / seller name  \n",
       "count           644                 639  \n",
       "unique            3                  15  \n",
       "top     Unspecified       PrettyfulShop  \n",
       "freq            505                 172  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "444b900d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(644, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37c786f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            count\n",
      "Category                         \n",
      "Jewelry                       151\n",
      "Vintage                        59\n",
      "Ornaments                      32\n",
      "POD                            28\n",
      "Stickers                       25\n",
      "Clothing                       23\n",
      "Philippine Handicrafts         22\n",
      "Digital Downloads              22\n",
      "Philippine Souvenir            18\n",
      "Pasko & Parols                 17\n",
      "Bundle Deals                   16\n",
      "Accessories                    16\n",
      "Wedding Ceremony               16\n",
      "Bags                           16\n",
      "Stickers/Decals                16\n",
      "Apparel                        13\n",
      "Keychains/Charms               13\n",
      "Filipiniana Attire             13\n",
      "Prints                         12\n",
      "Pinoy Keychains & Charms       10\n",
      "Vintage Movies                  9\n",
      "Stationery & Stickers           9\n",
      "Keychains                       8\n",
      "Native                          7\n",
      "Printables                      5\n",
      "Decor                           4\n",
      "Mugs                            4\n",
      "Art Prints                      3\n",
      "Capiz Decor                     3\n",
      "Motorcycle Accessories          3\n",
      "Pins                            3\n",
      "Home Goods                      3\n",
      "Jewelry & Pouches               2\n",
      "Car Accessories                 2\n",
      "Christmas Ornaments             2\n",
      "Pochette                        2\n",
      "Baybayin                        2\n",
      "Keychains/Hair Accessories      1\n",
      "Magnets                         1\n",
      "Hair Accessories                1\n",
      "Framed Prints                   1\n",
      "Face Bag                        1\n",
      "Greeting Cards                  1\n",
      "Objects                         1\n",
      "Reusable Bags                   1\n",
      "Bracelets                       1\n"
     ]
    }
   ],
   "source": [
    "category_df = df['Category'].value_counts().to_frame()\n",
    "print(category_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8db1c351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product name           0\n",
       "Product description    0\n",
       "Price                  0\n",
       "Category               0\n",
       "Subcategory            0\n",
       "Color                  0\n",
       "Size                   0\n",
       "Material               0\n",
       "Tags                   0\n",
       "Product link           0\n",
       "Image link             0\n",
       "Brand / seller name    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28583d08",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "- findings...\n",
    "- findings...\n",
    "\n",
    "---\n",
    "# Data Cleaning\n",
    "This section shows the critical data cleaning steps applied to the raw text datasets before feature engineering and pre-processing of the dataset. The goal of these steps is to transform noisy, unstructured text into a clean and consistent format.\n",
    "\n",
    "## Handle Missing Values\n",
    "Missing data (NaN) in text columns can cause errors or be treated as a useless string. It must be fill with a specific, non-empty placeholder like an empty string ('') before concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ae8a2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Product name', 'Product description', 'Price', 'Category',\n",
       "       'Subcategory', 'Color', 'Size', 'Material', 'Tags', 'Product link',\n",
       "       'Image link', 'Brand / seller name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning Column Names\n",
    "df.columns = df.columns.str.strip()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09e6f422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product name           0\n",
       "Product description    0\n",
       "Price                  0\n",
       "Category               0\n",
       "Subcategory            0\n",
       "Color                  0\n",
       "Size                   0\n",
       "Material               0\n",
       "Tags                   0\n",
       "Product link           0\n",
       "Image link             0\n",
       "Brand / seller name    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handling Missing Values\n",
    "df = df.fillna('')\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c0d82",
   "metadata": {},
   "source": [
    "## Handle Duplicate Rows \n",
    "description..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0773411a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(618, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handle duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b946a4f",
   "metadata": {},
   "source": [
    "## Handle Inconsistent Data\n",
    "lowercasing, removal of special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "979cf33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Whitespace standardized\n"
     ]
    }
   ],
   "source": [
    "# 1. Strip whitespace from all text columns\n",
    "df_clean = df.copy()\n",
    "\n",
    "text_columns = ['Product name', 'Product description', 'Category', 'Subcategory', 'Size', 'Material', 'Tags']\n",
    "\n",
    "for col in text_columns:\n",
    "    # Remove leading/trailing whitespace\n",
    "    df_clean[col] = df_clean[col].str.strip()\n",
    "    # Remove extra spaces between words (replace multiple spaces with single space)\n",
    "    df_clean[col] = df_clean[col].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "print(\"✓ Whitespace standardized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2c091e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Capitalization standardized\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT TITLE</th>\n",
       "      <th>PRODUCT DESCRIPTION</th>\n",
       "      <th>COLOR</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>MATERIAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Halo-Halo Keychain</td>\n",
       "      <td>Miniature halo-halo dessert keychain made from...</td>\n",
       "      <td>Transparent, Multi-Colored</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>Clay, Resin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Filipino Funny Magnets</td>\n",
       "      <td>A set of novelty refrigerator magnets featurin...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>2X2 INCHES</td>\n",
       "      <td>Vinyl-Coated Magnetic Sheet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Filipino Snacks Parody Stickers (Skyflakes, Su...</td>\n",
       "      <td>A set of Filipino parody snack stickers inspir...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>SUSMARYOSEP: 3.5 IN X 2 IN AND POTCHA: 3.25 IN...</td>\n",
       "      <td>Vinyl Sticker With Matte Finish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Philippine-Inspired Monogram Keychain</td>\n",
       "      <td>A 2-inch tall handmade keychain featuring a mo...</td>\n",
       "      <td>Red, Blue, Yellow</td>\n",
       "      <td>2 IN</td>\n",
       "      <td>Resin, Sticker, Glitter, Metal Findings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Filipino Dessert Drink Stickers: Taho and Iskr...</td>\n",
       "      <td>A pair of illustrated stickers inspired by ico...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>APPROX. 3 IN X 2.3 IN</td>\n",
       "      <td>Vinyl Sticker With Matte Finish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wala Akong Pake! - Filipino Plastic Bag Sticke...</td>\n",
       "      <td>A waterproof vinyl sticker designed as a playf...</td>\n",
       "      <td>White With Orange-Black Accents</td>\n",
       "      <td>APPROX. 3 IN X 2.75 IN</td>\n",
       "      <td>Vinyl Sticker With Matte Finish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I'm Not Late, I'm on Filipino Time! - Funny Fi...</td>\n",
       "      <td>A 3-inch vinyl sticker featuring a hand-drawn ...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>3 X 3 IN</td>\n",
       "      <td>Vinyl Sticker With Matte Finish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Isaw (Chicken Gizzard) - Philippine Street Foo...</td>\n",
       "      <td>A 3-inch vinyl sticker featuring a cartoon-sty...</td>\n",
       "      <td>Brown</td>\n",
       "      <td>3 X 3 IN</td>\n",
       "      <td>Vinyl Sticker With Matte Finish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Baguio-Inspired Barrel Man: A Wood Carved Stic...</td>\n",
       "      <td>A 4-inch vinyl sticker inspired by the iconic ...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>4 IN X 3 IN</td>\n",
       "      <td>Vinyl Sticker With Matte Finish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Laban Lang! - Motivational Sticker Tag</td>\n",
       "      <td>A 4-inch vinyl sticker featuring a pop-up wind...</td>\n",
       "      <td>Black/Yellow</td>\n",
       "      <td>APPROX. 4 IN X 1.25 IN</td>\n",
       "      <td>Vinyl, Ink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bilo-Bilo: Filipino Dessert Keychain (KCH-BLO-...</td>\n",
       "      <td>A handcrafted keychain inspired by Bilo-Bilo, ...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>APPROX. 2 IN TALL</td>\n",
       "      <td>Resin, Polymer Clay, Foam, Beads, Metal Keycha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Adulting Awards in Filipino Sticker Tags</td>\n",
       "      <td>A collection of vinyl stickers designed as col...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>APPROX. 4 IN X 2 IN</td>\n",
       "      <td>Vinyl, Ink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ay Nako, Girl! - Filipino Hugot Lines Sticker ...</td>\n",
       "      <td>A 3-inch vinyl sticker featuring the bold Taga...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>3 IN X 2 IN</td>\n",
       "      <td>Vinyl, Ink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fruit Salad: Filipino Dessert Keychain (KCH-FR...</td>\n",
       "      <td>A handcrafted keychain inspired by Fruit Salad...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>APPROX. 2 IN TALL</td>\n",
       "      <td>Resin, Polymer Clay, Foam, Beads, Metal Keycha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Buko Pandan: Filipino Dessert Keychain (KCH-BK...</td>\n",
       "      <td>A handcrafted keychain inspired by Buko Pandan...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>APPROX. 2 IN TALL</td>\n",
       "      <td>Resin, Polymer Clay, Foam, Beads, Metal Keycha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        PRODUCT TITLE  \\\n",
       "0                                  Halo-Halo Keychain   \n",
       "1                              Filipino Funny Magnets   \n",
       "2   Filipino Snacks Parody Stickers (Skyflakes, Su...   \n",
       "3               Philippine-Inspired Monogram Keychain   \n",
       "4   Filipino Dessert Drink Stickers: Taho and Iskr...   \n",
       "5   Wala Akong Pake! - Filipino Plastic Bag Sticke...   \n",
       "6   I'm Not Late, I'm on Filipino Time! - Funny Fi...   \n",
       "7   Isaw (Chicken Gizzard) - Philippine Street Foo...   \n",
       "8   Baguio-Inspired Barrel Man: A Wood Carved Stic...   \n",
       "9              Laban Lang! - Motivational Sticker Tag   \n",
       "10  Bilo-Bilo: Filipino Dessert Keychain (KCH-BLO-...   \n",
       "11           Adulting Awards in Filipino Sticker Tags   \n",
       "12  Ay Nako, Girl! - Filipino Hugot Lines Sticker ...   \n",
       "13  Fruit Salad: Filipino Dessert Keychain (KCH-FR...   \n",
       "14  Buko Pandan: Filipino Dessert Keychain (KCH-BK...   \n",
       "\n",
       "                                  PRODUCT DESCRIPTION  \\\n",
       "0   Miniature halo-halo dessert keychain made from...   \n",
       "1   A set of novelty refrigerator magnets featurin...   \n",
       "2   A set of Filipino parody snack stickers inspir...   \n",
       "3   A 2-inch tall handmade keychain featuring a mo...   \n",
       "4   A pair of illustrated stickers inspired by ico...   \n",
       "5   A waterproof vinyl sticker designed as a playf...   \n",
       "6   A 3-inch vinyl sticker featuring a hand-drawn ...   \n",
       "7   A 3-inch vinyl sticker featuring a cartoon-sty...   \n",
       "8   A 4-inch vinyl sticker inspired by the iconic ...   \n",
       "9   A 4-inch vinyl sticker featuring a pop-up wind...   \n",
       "10  A handcrafted keychain inspired by Bilo-Bilo, ...   \n",
       "11  A collection of vinyl stickers designed as col...   \n",
       "12  A 3-inch vinyl sticker featuring the bold Taga...   \n",
       "13  A handcrafted keychain inspired by Fruit Salad...   \n",
       "14  A handcrafted keychain inspired by Buko Pandan...   \n",
       "\n",
       "                              COLOR  \\\n",
       "0        Transparent, Multi-Colored   \n",
       "1                     Multi-Colored   \n",
       "2                     Multi-Colored   \n",
       "3                 Red, Blue, Yellow   \n",
       "4                     Multi-Colored   \n",
       "5   White With Orange-Black Accents   \n",
       "6                     Multi-Colored   \n",
       "7                             Brown   \n",
       "8                     Multi-Colored   \n",
       "9                      Black/Yellow   \n",
       "10                    Multi-Colored   \n",
       "11                    Multi-Colored   \n",
       "12                    Multi-Colored   \n",
       "13                    Multi-Colored   \n",
       "14                    Multi-Colored   \n",
       "\n",
       "                                                 SIZE  \\\n",
       "0                                               SMALL   \n",
       "1                                          2X2 INCHES   \n",
       "2   SUSMARYOSEP: 3.5 IN X 2 IN AND POTCHA: 3.25 IN...   \n",
       "3                                                2 IN   \n",
       "4                               APPROX. 3 IN X 2.3 IN   \n",
       "5                              APPROX. 3 IN X 2.75 IN   \n",
       "6                                            3 X 3 IN   \n",
       "7                                            3 X 3 IN   \n",
       "8                                         4 IN X 3 IN   \n",
       "9                              APPROX. 4 IN X 1.25 IN   \n",
       "10                                  APPROX. 2 IN TALL   \n",
       "11                                APPROX. 4 IN X 2 IN   \n",
       "12                                        3 IN X 2 IN   \n",
       "13                                  APPROX. 2 IN TALL   \n",
       "14                                  APPROX. 2 IN TALL   \n",
       "\n",
       "                                             MATERIAL  \n",
       "0                                         Clay, Resin  \n",
       "1                         Vinyl-Coated Magnetic Sheet  \n",
       "2                     Vinyl Sticker With Matte Finish  \n",
       "3             Resin, Sticker, Glitter, Metal Findings  \n",
       "4                     Vinyl Sticker With Matte Finish  \n",
       "5                     Vinyl Sticker With Matte Finish  \n",
       "6                     Vinyl Sticker With Matte Finish  \n",
       "7                     Vinyl Sticker With Matte Finish  \n",
       "8                     Vinyl Sticker With Matte Finish  \n",
       "9                                          Vinyl, Ink  \n",
       "10  Resin, Polymer Clay, Foam, Beads, Metal Keycha...  \n",
       "11                                         Vinyl, Ink  \n",
       "12                                         Vinyl, Ink  \n",
       "13  Resin, Polymer Clay, Foam, Beads, Metal Keycha...  \n",
       "14  Resin, Polymer Clay, Foam, Beads, Metal Keycha...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Fix inconsistent capitalization in Categorical Data Columns\n",
    "\n",
    "# Standardize COLOR field\n",
    "df_clean['COLOR'] = df_clean['COLOR'].str.title()\n",
    "\n",
    "# standardize SIZE field\n",
    "df_clean['SIZE'] = df_clean['SIZE'].str.upper()\n",
    "\n",
    "# Standardize MATERIAL field\n",
    "df_clean['MATERIAL'] = df_clean['MATERIAL'].str.title()\n",
    "\n",
    "print(\"✓ Capitalization standardized\")\n",
    "df_clean.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf6f706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Size formatting standardized\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT TITLE</th>\n",
       "      <th>PRODUCT DESCRIPTION</th>\n",
       "      <th>COLOR</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>MATERIAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Halo-Halo Keychain</td>\n",
       "      <td>Miniature halo-halo dessert keychain made from...</td>\n",
       "      <td>Transparent, Multi-Colored</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>Clay, Resin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Filipino Funny Magnets</td>\n",
       "      <td>A set of novelty refrigerator magnets featurin...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>2 x 2 in</td>\n",
       "      <td>Vinyl-Coated Magnetic Sheet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Filipino Snacks Parody Stickers (Skyflakes, Su...</td>\n",
       "      <td>A set of Filipino parody snack stickers inspir...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>SUSMARYOSEP: 3.5 IN x 2 IN AND POTCHA: 3.25 IN...</td>\n",
       "      <td>Vinyl Sticker With Matte Finish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Philippine-Inspired Monogram Keychain</td>\n",
       "      <td>A 2-inch tall handmade keychain featuring a mo...</td>\n",
       "      <td>Red, Blue, Yellow</td>\n",
       "      <td>2 IN</td>\n",
       "      <td>Resin, Sticker, Glitter, Metal Findings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Filipino Dessert Drink Stickers: Taho and Iskr...</td>\n",
       "      <td>A pair of illustrated stickers inspired by ico...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>APPRO x . 3 IN x 2.3 IN</td>\n",
       "      <td>Vinyl Sticker With Matte Finish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wala Akong Pake! - Filipino Plastic Bag Sticke...</td>\n",
       "      <td>A waterproof vinyl sticker designed as a playf...</td>\n",
       "      <td>White With Orange-Black Accents</td>\n",
       "      <td>APPRO x . 3 IN x 2.75 IN</td>\n",
       "      <td>Vinyl Sticker With Matte Finish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I'm Not Late, I'm on Filipino Time! - Funny Fi...</td>\n",
       "      <td>A 3-inch vinyl sticker featuring a hand-drawn ...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>3 x 3 IN</td>\n",
       "      <td>Vinyl Sticker With Matte Finish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Isaw (Chicken Gizzard) - Philippine Street Foo...</td>\n",
       "      <td>A 3-inch vinyl sticker featuring a cartoon-sty...</td>\n",
       "      <td>Brown</td>\n",
       "      <td>3 x 3 IN</td>\n",
       "      <td>Vinyl Sticker With Matte Finish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Baguio-Inspired Barrel Man: A Wood Carved Stic...</td>\n",
       "      <td>A 4-inch vinyl sticker inspired by the iconic ...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>4 IN x 3 IN</td>\n",
       "      <td>Vinyl Sticker With Matte Finish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Laban Lang! - Motivational Sticker Tag</td>\n",
       "      <td>A 4-inch vinyl sticker featuring a pop-up wind...</td>\n",
       "      <td>Black/Yellow</td>\n",
       "      <td>APPRO x . 4 IN x 1.25 IN</td>\n",
       "      <td>Vinyl, Ink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bilo-Bilo: Filipino Dessert Keychain (KCH-BLO-...</td>\n",
       "      <td>A handcrafted keychain inspired by Bilo-Bilo, ...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>APPRO x . 2 IN TALL</td>\n",
       "      <td>Resin, Polymer Clay, Foam, Beads, Metal Keycha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Adulting Awards in Filipino Sticker Tags</td>\n",
       "      <td>A collection of vinyl stickers designed as col...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>APPRO x . 4 IN x 2 IN</td>\n",
       "      <td>Vinyl, Ink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ay Nako, Girl! - Filipino Hugot Lines Sticker ...</td>\n",
       "      <td>A 3-inch vinyl sticker featuring the bold Taga...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>3 IN x 2 IN</td>\n",
       "      <td>Vinyl, Ink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fruit Salad: Filipino Dessert Keychain (KCH-FR...</td>\n",
       "      <td>A handcrafted keychain inspired by Fruit Salad...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>APPRO x . 2 IN TALL</td>\n",
       "      <td>Resin, Polymer Clay, Foam, Beads, Metal Keycha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Buko Pandan: Filipino Dessert Keychain (KCH-BK...</td>\n",
       "      <td>A handcrafted keychain inspired by Buko Pandan...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>APPRO x . 2 IN TALL</td>\n",
       "      <td>Resin, Polymer Clay, Foam, Beads, Metal Keycha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        PRODUCT TITLE  \\\n",
       "0                                  Halo-Halo Keychain   \n",
       "1                              Filipino Funny Magnets   \n",
       "2   Filipino Snacks Parody Stickers (Skyflakes, Su...   \n",
       "3               Philippine-Inspired Monogram Keychain   \n",
       "4   Filipino Dessert Drink Stickers: Taho and Iskr...   \n",
       "5   Wala Akong Pake! - Filipino Plastic Bag Sticke...   \n",
       "6   I'm Not Late, I'm on Filipino Time! - Funny Fi...   \n",
       "7   Isaw (Chicken Gizzard) - Philippine Street Foo...   \n",
       "8   Baguio-Inspired Barrel Man: A Wood Carved Stic...   \n",
       "9              Laban Lang! - Motivational Sticker Tag   \n",
       "10  Bilo-Bilo: Filipino Dessert Keychain (KCH-BLO-...   \n",
       "11           Adulting Awards in Filipino Sticker Tags   \n",
       "12  Ay Nako, Girl! - Filipino Hugot Lines Sticker ...   \n",
       "13  Fruit Salad: Filipino Dessert Keychain (KCH-FR...   \n",
       "14  Buko Pandan: Filipino Dessert Keychain (KCH-BK...   \n",
       "\n",
       "                                  PRODUCT DESCRIPTION  \\\n",
       "0   Miniature halo-halo dessert keychain made from...   \n",
       "1   A set of novelty refrigerator magnets featurin...   \n",
       "2   A set of Filipino parody snack stickers inspir...   \n",
       "3   A 2-inch tall handmade keychain featuring a mo...   \n",
       "4   A pair of illustrated stickers inspired by ico...   \n",
       "5   A waterproof vinyl sticker designed as a playf...   \n",
       "6   A 3-inch vinyl sticker featuring a hand-drawn ...   \n",
       "7   A 3-inch vinyl sticker featuring a cartoon-sty...   \n",
       "8   A 4-inch vinyl sticker inspired by the iconic ...   \n",
       "9   A 4-inch vinyl sticker featuring a pop-up wind...   \n",
       "10  A handcrafted keychain inspired by Bilo-Bilo, ...   \n",
       "11  A collection of vinyl stickers designed as col...   \n",
       "12  A 3-inch vinyl sticker featuring the bold Taga...   \n",
       "13  A handcrafted keychain inspired by Fruit Salad...   \n",
       "14  A handcrafted keychain inspired by Buko Pandan...   \n",
       "\n",
       "                              COLOR  \\\n",
       "0        Transparent, Multi-Colored   \n",
       "1                     Multi-Colored   \n",
       "2                     Multi-Colored   \n",
       "3                 Red, Blue, Yellow   \n",
       "4                     Multi-Colored   \n",
       "5   White With Orange-Black Accents   \n",
       "6                     Multi-Colored   \n",
       "7                             Brown   \n",
       "8                     Multi-Colored   \n",
       "9                      Black/Yellow   \n",
       "10                    Multi-Colored   \n",
       "11                    Multi-Colored   \n",
       "12                    Multi-Colored   \n",
       "13                    Multi-Colored   \n",
       "14                    Multi-Colored   \n",
       "\n",
       "                                                 SIZE  \\\n",
       "0                                               SMALL   \n",
       "1                                            2 x 2 in   \n",
       "2   SUSMARYOSEP: 3.5 IN x 2 IN AND POTCHA: 3.25 IN...   \n",
       "3                                                2 IN   \n",
       "4                             APPRO x . 3 IN x 2.3 IN   \n",
       "5                            APPRO x . 3 IN x 2.75 IN   \n",
       "6                                            3 x 3 IN   \n",
       "7                                            3 x 3 IN   \n",
       "8                                         4 IN x 3 IN   \n",
       "9                            APPRO x . 4 IN x 1.25 IN   \n",
       "10                                APPRO x . 2 IN TALL   \n",
       "11                              APPRO x . 4 IN x 2 IN   \n",
       "12                                        3 IN x 2 IN   \n",
       "13                                APPRO x . 2 IN TALL   \n",
       "14                                APPRO x . 2 IN TALL   \n",
       "\n",
       "                                             MATERIAL  \n",
       "0                                         Clay, Resin  \n",
       "1                         Vinyl-Coated Magnetic Sheet  \n",
       "2                     Vinyl Sticker With Matte Finish  \n",
       "3             Resin, Sticker, Glitter, Metal Findings  \n",
       "4                     Vinyl Sticker With Matte Finish  \n",
       "5                     Vinyl Sticker With Matte Finish  \n",
       "6                     Vinyl Sticker With Matte Finish  \n",
       "7                     Vinyl Sticker With Matte Finish  \n",
       "8                     Vinyl Sticker With Matte Finish  \n",
       "9                                          Vinyl, Ink  \n",
       "10  Resin, Polymer Clay, Foam, Beads, Metal Keycha...  \n",
       "11                                         Vinyl, Ink  \n",
       "12                                         Vinyl, Ink  \n",
       "13  Resin, Polymer Clay, Foam, Beads, Metal Keycha...  \n",
       "14  Resin, Polymer Clay, Foam, Beads, Metal Keycha...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Standardize SIZE format inconsistencies\n",
    "def standardize_size(size_str):\n",
    "    \"\"\"Standardize size formatting\"\"\"\n",
    "    if pd.isna(size_str) or size_str == '':\n",
    "        return ''\n",
    "    \n",
    "    size_str = str(size_str).strip()\n",
    "    \n",
    "    # Standardize \"inches\" variations\n",
    "    size_str = re.sub(r'\\binches\\b', 'in', size_str, flags=re.IGNORECASE)\n",
    "    size_str = re.sub(r'\\binch\\b', 'in', size_str, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Standardize \"x\" separator (remove spaces around 'x')\n",
    "    size_str = re.sub(r'\\s*x\\s*', ' x ', size_str, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Standardize \"approx.\" variations\n",
    "    size_str = re.sub(r'\\bapprox\\.?\\b', 'Approx.', size_str, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Standardize \"diameter\"\n",
    "    size_str = re.sub(r'\\bdiameter\\b', 'diameter', size_str, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Handle \"Unidentified\" consistently\n",
    "    if size_str.lower() == 'unidentified':\n",
    "        return 'Unidentified'\n",
    "    \n",
    "    return size_str.strip()\n",
    "\n",
    "df_clean['SIZE'] = df_clean['SIZE'].apply(standardize_size)\n",
    "\n",
    "print(\"✓ Size formatting standardized\")\n",
    "df_clean.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fb574c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Material names standardized\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT TITLE</th>\n",
       "      <th>PRODUCT DESCRIPTION</th>\n",
       "      <th>COLOR</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>MATERIAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Halo-Halo Keychain</td>\n",
       "      <td>Miniature halo-halo dessert keychain made from...</td>\n",
       "      <td>Transparent, Multi-Colored</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>Clay, Resin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Filipino Funny Magnets</td>\n",
       "      <td>A set of novelty refrigerator magnets featurin...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>2 x 2 in</td>\n",
       "      <td>Vinyl-Coated Magnetic Sheet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Filipino Snacks Parody Stickers (Skyflakes, Su...</td>\n",
       "      <td>A set of Filipino parody snack stickers inspir...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>SUSMARYOSEP: 3.5 IN x 2 IN AND POTCHA: 3.25 IN...</td>\n",
       "      <td>Vinyl Sticker (Matte Finish)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Philippine-Inspired Monogram Keychain</td>\n",
       "      <td>A 2-inch tall handmade keychain featuring a mo...</td>\n",
       "      <td>Red, Blue, Yellow</td>\n",
       "      <td>2 IN</td>\n",
       "      <td>Resin, Sticker, Glitter, Metal Findings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Filipino Dessert Drink Stickers: Taho and Iskr...</td>\n",
       "      <td>A pair of illustrated stickers inspired by ico...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>APPRO x . 3 IN x 2.3 IN</td>\n",
       "      <td>Vinyl Sticker (Matte Finish)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wala Akong Pake! - Filipino Plastic Bag Sticke...</td>\n",
       "      <td>A waterproof vinyl sticker designed as a playf...</td>\n",
       "      <td>White With Orange-Black Accents</td>\n",
       "      <td>APPRO x . 3 IN x 2.75 IN</td>\n",
       "      <td>Vinyl Sticker (Matte Finish)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I'm Not Late, I'm on Filipino Time! - Funny Fi...</td>\n",
       "      <td>A 3-inch vinyl sticker featuring a hand-drawn ...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>3 x 3 IN</td>\n",
       "      <td>Vinyl Sticker (Matte Finish)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Isaw (Chicken Gizzard) - Philippine Street Foo...</td>\n",
       "      <td>A 3-inch vinyl sticker featuring a cartoon-sty...</td>\n",
       "      <td>Brown</td>\n",
       "      <td>3 x 3 IN</td>\n",
       "      <td>Vinyl Sticker (Matte Finish)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Baguio-Inspired Barrel Man: A Wood Carved Stic...</td>\n",
       "      <td>A 4-inch vinyl sticker inspired by the iconic ...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>4 IN x 3 IN</td>\n",
       "      <td>Vinyl Sticker (Matte Finish)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Laban Lang! - Motivational Sticker Tag</td>\n",
       "      <td>A 4-inch vinyl sticker featuring a pop-up wind...</td>\n",
       "      <td>Black/Yellow</td>\n",
       "      <td>APPRO x . 4 IN x 1.25 IN</td>\n",
       "      <td>Vinyl, Ink</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       PRODUCT TITLE  \\\n",
       "0                                 Halo-Halo Keychain   \n",
       "1                             Filipino Funny Magnets   \n",
       "2  Filipino Snacks Parody Stickers (Skyflakes, Su...   \n",
       "3              Philippine-Inspired Monogram Keychain   \n",
       "4  Filipino Dessert Drink Stickers: Taho and Iskr...   \n",
       "5  Wala Akong Pake! - Filipino Plastic Bag Sticke...   \n",
       "6  I'm Not Late, I'm on Filipino Time! - Funny Fi...   \n",
       "7  Isaw (Chicken Gizzard) - Philippine Street Foo...   \n",
       "8  Baguio-Inspired Barrel Man: A Wood Carved Stic...   \n",
       "9             Laban Lang! - Motivational Sticker Tag   \n",
       "\n",
       "                                 PRODUCT DESCRIPTION  \\\n",
       "0  Miniature halo-halo dessert keychain made from...   \n",
       "1  A set of novelty refrigerator magnets featurin...   \n",
       "2  A set of Filipino parody snack stickers inspir...   \n",
       "3  A 2-inch tall handmade keychain featuring a mo...   \n",
       "4  A pair of illustrated stickers inspired by ico...   \n",
       "5  A waterproof vinyl sticker designed as a playf...   \n",
       "6  A 3-inch vinyl sticker featuring a hand-drawn ...   \n",
       "7  A 3-inch vinyl sticker featuring a cartoon-sty...   \n",
       "8  A 4-inch vinyl sticker inspired by the iconic ...   \n",
       "9  A 4-inch vinyl sticker featuring a pop-up wind...   \n",
       "\n",
       "                             COLOR  \\\n",
       "0       Transparent, Multi-Colored   \n",
       "1                    Multi-Colored   \n",
       "2                    Multi-Colored   \n",
       "3                Red, Blue, Yellow   \n",
       "4                    Multi-Colored   \n",
       "5  White With Orange-Black Accents   \n",
       "6                    Multi-Colored   \n",
       "7                            Brown   \n",
       "8                    Multi-Colored   \n",
       "9                     Black/Yellow   \n",
       "\n",
       "                                                SIZE  \\\n",
       "0                                              SMALL   \n",
       "1                                           2 x 2 in   \n",
       "2  SUSMARYOSEP: 3.5 IN x 2 IN AND POTCHA: 3.25 IN...   \n",
       "3                                               2 IN   \n",
       "4                            APPRO x . 3 IN x 2.3 IN   \n",
       "5                           APPRO x . 3 IN x 2.75 IN   \n",
       "6                                           3 x 3 IN   \n",
       "7                                           3 x 3 IN   \n",
       "8                                        4 IN x 3 IN   \n",
       "9                           APPRO x . 4 IN x 1.25 IN   \n",
       "\n",
       "                                  MATERIAL  \n",
       "0                              Clay, Resin  \n",
       "1              Vinyl-Coated Magnetic Sheet  \n",
       "2             Vinyl Sticker (Matte Finish)  \n",
       "3  Resin, Sticker, Glitter, Metal Findings  \n",
       "4             Vinyl Sticker (Matte Finish)  \n",
       "5             Vinyl Sticker (Matte Finish)  \n",
       "6             Vinyl Sticker (Matte Finish)  \n",
       "7             Vinyl Sticker (Matte Finish)  \n",
       "8             Vinyl Sticker (Matte Finish)  \n",
       "9                               Vinyl, Ink  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Standardize MATERIAL field\n",
    "def standardize_materials(material_str):\n",
    "    \"\"\"Standardize material names and formatting\"\"\"\n",
    "    if pd.isna(material_str) or material_str == '':\n",
    "        return ''\n",
    "    \n",
    "    material_str = str(material_str).strip()\n",
    "    \n",
    "    # Split by comma, clean each material, and rejoin\n",
    "    materials = [m.strip() for m in material_str.split(',')]\n",
    "    \n",
    "    # Standardize common material names\n",
    "    material_mapping = {\n",
    "        'resin': 'Resin',\n",
    "        'clay': 'Clay',\n",
    "        'polymer clay': 'Polymer Clay',\n",
    "        'vinyl': 'Vinyl',\n",
    "        'ink': 'Ink',\n",
    "        'foam': 'Foam',\n",
    "        'beads': 'Beads',\n",
    "        'metal': 'Metal',\n",
    "        'glitter': 'Glitter',\n",
    "        'sticker': 'Sticker',\n",
    "        'vinyl sticker with matte finish': 'Vinyl Sticker (Matte Finish)',\n",
    "        'vinyl-coated magnetic sheet': 'Vinyl-Coated Magnetic Sheet',\n",
    "        'capiz shell': 'Capiz Shell',\n",
    "        'brass': 'Brass',\n",
    "        'pearl': 'Pearl',\n",
    "        'silk organza': 'Silk Organza',\n",
    "        'stainless steel': 'Stainless Steel',\n",
    "        'polysatin': 'Polysatin',\n",
    "        'canvas': 'Canvas',\n",
    "        'zipper': 'Zipper'\n",
    "    }\n",
    "    \n",
    "    standardized_materials = []\n",
    "    for mat in materials:\n",
    "        mat_lower = mat.lower().strip()\n",
    "        standardized = material_mapping.get(mat_lower, mat.title())\n",
    "        standardized_materials.append(standardized)\n",
    "    \n",
    "    return ', '.join(standardized_materials)\n",
    "\n",
    "df_clean['MATERIAL'] = df_clean['MATERIAL'].apply(standardize_materials)\n",
    "\n",
    "print(\"✓ Material names standardized\")\n",
    "df_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4cc384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Special characters cleaned\n"
     ]
    }
   ],
   "source": [
    "# 5. Fix special characters and encoding issues\n",
    "def clean_special_chars(text):\n",
    "    \"\"\"Remove or replace problematic special characters\"\"\"\n",
    "    if pd.isna(text) or text == '':\n",
    "        return ''\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    # Replace problematic quotes\n",
    "    text = text.replace('\"', '\"').replace('\"', '\"')\n",
    "    text = text.replace(''', \"'\").replace(''', \"'\")\n",
    "    \n",
    "    # Remove zero-width spaces and other invisible characters\n",
    "    text = re.sub(r'[\\u200b-\\u200f\\u202a-\\u202e\\ufeff]', '', text)\n",
    "    \n",
    "    # Normalize em-dash and en-dash\n",
    "    text = text.replace('—', '-').replace('–', '-')\n",
    "    \n",
    "    return text\n",
    "\n",
    "for col in text_columns:\n",
    "    df_clean[col] = df_clean[col].apply(clean_special_chars)\n",
    "\n",
    "print(\"✓ Special characters cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2ad56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Description terms standardized\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT TITLE</th>\n",
       "      <th>PRODUCT DESCRIPTION</th>\n",
       "      <th>COLOR</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>MATERIAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Halo-Halo Keychain</td>\n",
       "      <td>Miniature halo-halo dessert keychain made from...</td>\n",
       "      <td>Transparent, Multi-Colored</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>Clay, Resin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Filipino Funny Magnets</td>\n",
       "      <td>A set of novelty refrigerator magnets featurin...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>2 x 2 in</td>\n",
       "      <td>Vinyl-Coated Magnetic Sheet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Filipino Snacks Parody Stickers (Skyflakes, Su...</td>\n",
       "      <td>A set of Filipino parody snack stickers inspir...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>SUSMARYOSEP: 3.5 IN x 2 IN AND POTCHA: 3.25 IN...</td>\n",
       "      <td>Vinyl Sticker (Matte Finish)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Philippine-Inspired Monogram Keychain</td>\n",
       "      <td>A 2-in tall handmade keychain featuring a mono...</td>\n",
       "      <td>Red, Blue, Yellow</td>\n",
       "      <td>2 IN</td>\n",
       "      <td>Resin, Sticker, Glitter, Metal Findings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Filipino Dessert Drink Stickers: Taho and Iskr...</td>\n",
       "      <td>A pair of illustrated stickers inspired by ico...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>APPRO x . 3 IN x 2.3 IN</td>\n",
       "      <td>Vinyl Sticker (Matte Finish)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wala Akong Pake! - Filipino Plastic Bag Sticke...</td>\n",
       "      <td>A waterproof vinyl sticker designed as a playf...</td>\n",
       "      <td>White With Orange-Black Accents</td>\n",
       "      <td>APPRO x . 3 IN x 2.75 IN</td>\n",
       "      <td>Vinyl Sticker (Matte Finish)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I'm Not Late, I'm on Filipino Time! - Funny Fi...</td>\n",
       "      <td>A 3-in vinyl sticker featuring a hand-drawn wr...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>3 x 3 IN</td>\n",
       "      <td>Vinyl Sticker (Matte Finish)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Isaw (Chicken Gizzard) - Philippine Street Foo...</td>\n",
       "      <td>A 3-in vinyl sticker featuring a cartoon-style...</td>\n",
       "      <td>Brown</td>\n",
       "      <td>3 x 3 IN</td>\n",
       "      <td>Vinyl Sticker (Matte Finish)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Baguio-Inspired Barrel Man: A Wood Carved Stic...</td>\n",
       "      <td>A 4-in vinyl sticker inspired by the iconic Ba...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>4 IN x 3 IN</td>\n",
       "      <td>Vinyl Sticker (Matte Finish)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Laban Lang! - Motivational Sticker Tag</td>\n",
       "      <td>A 4-in vinyl sticker featuring a pop-up window...</td>\n",
       "      <td>Black/Yellow</td>\n",
       "      <td>APPRO x . 4 IN x 1.25 IN</td>\n",
       "      <td>Vinyl, Ink</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       PRODUCT TITLE  \\\n",
       "0                                 Halo-Halo Keychain   \n",
       "1                             Filipino Funny Magnets   \n",
       "2  Filipino Snacks Parody Stickers (Skyflakes, Su...   \n",
       "3              Philippine-Inspired Monogram Keychain   \n",
       "4  Filipino Dessert Drink Stickers: Taho and Iskr...   \n",
       "5  Wala Akong Pake! - Filipino Plastic Bag Sticke...   \n",
       "6  I'm Not Late, I'm on Filipino Time! - Funny Fi...   \n",
       "7  Isaw (Chicken Gizzard) - Philippine Street Foo...   \n",
       "8  Baguio-Inspired Barrel Man: A Wood Carved Stic...   \n",
       "9             Laban Lang! - Motivational Sticker Tag   \n",
       "\n",
       "                                 PRODUCT DESCRIPTION  \\\n",
       "0  Miniature halo-halo dessert keychain made from...   \n",
       "1  A set of novelty refrigerator magnets featurin...   \n",
       "2  A set of Filipino parody snack stickers inspir...   \n",
       "3  A 2-in tall handmade keychain featuring a mono...   \n",
       "4  A pair of illustrated stickers inspired by ico...   \n",
       "5  A waterproof vinyl sticker designed as a playf...   \n",
       "6  A 3-in vinyl sticker featuring a hand-drawn wr...   \n",
       "7  A 3-in vinyl sticker featuring a cartoon-style...   \n",
       "8  A 4-in vinyl sticker inspired by the iconic Ba...   \n",
       "9  A 4-in vinyl sticker featuring a pop-up window...   \n",
       "\n",
       "                             COLOR  \\\n",
       "0       Transparent, Multi-Colored   \n",
       "1                    Multi-Colored   \n",
       "2                    Multi-Colored   \n",
       "3                Red, Blue, Yellow   \n",
       "4                    Multi-Colored   \n",
       "5  White With Orange-Black Accents   \n",
       "6                    Multi-Colored   \n",
       "7                            Brown   \n",
       "8                    Multi-Colored   \n",
       "9                     Black/Yellow   \n",
       "\n",
       "                                                SIZE  \\\n",
       "0                                              SMALL   \n",
       "1                                           2 x 2 in   \n",
       "2  SUSMARYOSEP: 3.5 IN x 2 IN AND POTCHA: 3.25 IN...   \n",
       "3                                               2 IN   \n",
       "4                            APPRO x . 3 IN x 2.3 IN   \n",
       "5                           APPRO x . 3 IN x 2.75 IN   \n",
       "6                                           3 x 3 IN   \n",
       "7                                           3 x 3 IN   \n",
       "8                                        4 IN x 3 IN   \n",
       "9                           APPRO x . 4 IN x 1.25 IN   \n",
       "\n",
       "                                  MATERIAL  \n",
       "0                              Clay, Resin  \n",
       "1              Vinyl-Coated Magnetic Sheet  \n",
       "2             Vinyl Sticker (Matte Finish)  \n",
       "3  Resin, Sticker, Glitter, Metal Findings  \n",
       "4             Vinyl Sticker (Matte Finish)  \n",
       "5             Vinyl Sticker (Matte Finish)  \n",
       "6             Vinyl Sticker (Matte Finish)  \n",
       "7             Vinyl Sticker (Matte Finish)  \n",
       "8             Vinyl Sticker (Matte Finish)  \n",
       "9                               Vinyl, Ink  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Standardize common terms in PRODUCT DESCRIPTION\n",
    "def standardize_description_terms(desc):\n",
    "    \"\"\"Standardize common terms and phrases in descriptions\"\"\"\n",
    "    if pd.isna(desc) or desc == '':\n",
    "        return ''\n",
    "    \n",
    "    desc = str(desc)\n",
    "    \n",
    "    # Standardize measurement units\n",
    "    desc = re.sub(r'\\binches\\b', 'in', desc, flags=re.IGNORECASE)\n",
    "    desc = re.sub(r'\\binch\\b', 'in', desc, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Standardize \"handmade/hand-made/hand made\"\n",
    "    desc = re.sub(r'\\bhand[\\s-]?made\\b', 'handmade', desc, flags=re.IGNORECASE)\n",
    "    desc = re.sub(r'\\bhand[\\s-]?crafted\\b', 'handcrafted', desc, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Standardize product type terms\n",
    "    desc = re.sub(r'\\bkey[\\s-]?chain\\b', 'keychain', desc, flags=re.IGNORECASE)\n",
    "    desc = re.sub(r'\\bwater[\\s-]?proof\\b', 'waterproof', desc, flags=re.IGNORECASE)\n",
    "    \n",
    "    return desc\n",
    "\n",
    "df_clean['PRODUCT DESCRIPTION'] = df_clean['PRODUCT DESCRIPTION'].apply(standardize_description_terms)\n",
    "\n",
    "print(\"✓ Description terms standardized\")\n",
    "df_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df8417c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "INCONSISTENCY REPORT\n",
      "============================================================\n",
      "\n",
      "Unique COLOR values (17):\n",
      "COLOR\n",
      "Multi-Colored                      30\n",
      "Translucent White/Gold              3\n",
      "Transparent, Multi-Colored          2\n",
      "Red, Blue, Yellow, White            2\n",
      "Antique Brass                       2\n",
      "Black/Yellow                        1\n",
      "Red, Blue, Yellow                   1\n",
      "White With Orange-Black Accents     1\n",
      "Brown                               1\n",
      "White/Red/Pink                      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique SIZE values (37):\n",
      "SIZE\n",
      "3 IN x 3 IN                                                 6\n",
      "Unidentified                                                4\n",
      "APPRO x . 2 IN TALL                                         3\n",
      "3 x 3 IN                                                    2\n",
      "SMALL                                                       2\n",
      "APPRO x . 4 IN x 2 IN                                       2\n",
      "APPRO x . 4 IN x 1.25 IN                                    2\n",
      "SUSMARYOSEP: 3.5 IN x 2 IN AND POTCHA: 3.25 IN x 1.75 IN    1\n",
      "2 x 2 in                                                    1\n",
      "APPRO x . 3 IN x 2.3 IN                                     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique MATERIAL values (20):\n",
      "MATERIAL\n",
      "Vinyl, Ink                                               21\n",
      "Vinyl Sticker (Matte Finish)                              6\n",
      "Resin, Polymer Clay, Foam, Beads                          4\n",
      "Resin, Polymer Clay, Foam, Beads, Metal Keychain Ring     3\n",
      "Capiz Shell, Metal Frame                                  2\n",
      "Resin, Sticker, Glitter, Metal Findings                   1\n",
      "Clay, Resin                                               1\n",
      "Vinyl-Coated Magnetic Sheet                               1\n",
      "Clay, Glaze                                               1\n",
      "Resin, Glitter, Earring Hardware                          1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "BEFORE vs AFTER COMPARISON (Sample)\n",
      "============================================================\n",
      "\n",
      "Row 2 - ORIGINAL:\n",
      "Size: 'Susmaryosep: 3.5 in x 2 in and Potcha: 3.25 in x 1.75 in'\n",
      "Material: 'Vinyl sticker with matte finish'\n",
      "\n",
      "Row 2 - CLEANED:\n",
      "Size: 'SUSMARYOSEP: 3.5 IN x 2 IN AND POTCHA: 3.25 IN x 1.75 IN'\n",
      "Material: 'Vinyl Sticker (Matte Finish)'\n",
      "\n",
      "✓ Data cleaning completed successfully!\n",
      "\n",
      "Shape: (51, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 7. Check for and report remaining inconsistencies\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INCONSISTENCY REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check COLOR field\n",
    "unique_colors = df_clean['COLOR'].value_counts()\n",
    "print(f\"\\nUnique COLOR values ({len(unique_colors)}):\")\n",
    "print(unique_colors.head(10))\n",
    "\n",
    "# Check SIZE patterns\n",
    "unique_sizes = df_clean['SIZE'].value_counts()\n",
    "print(f\"\\nUnique SIZE values ({len(unique_sizes)}):\")\n",
    "print(unique_sizes.head(10))\n",
    "\n",
    "# Check MATERIAL patterns\n",
    "unique_materials = df_clean['MATERIAL'].value_counts()\n",
    "print(f\"\\nUnique MATERIAL values ({len(unique_materials)}):\")\n",
    "print(unique_materials.head(10))\n",
    "\n",
    "# 8. Display before/after comparison for verification\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BEFORE vs AFTER COMPARISON (Sample)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "sample_idx = 2  # You can change this to check different rows\n",
    "print(f\"\\nRow {sample_idx} - ORIGINAL:\")\n",
    "print(f\"Size: '{df.loc[sample_idx, 'SIZE']}'\")\n",
    "print(f\"Material: '{df.loc[sample_idx, 'MATERIAL']}'\")\n",
    "\n",
    "print(f\"\\nRow {sample_idx} - CLEANED:\")\n",
    "print(f\"Size: '{df_clean.loc[sample_idx, 'SIZE']}'\")\n",
    "print(f\"Material: '{df_clean.loc[sample_idx, 'MATERIAL']}'\")\n",
    "\n",
    "print(\"\\n✓ Data cleaning completed successfully!\")\n",
    "print(f\"\\nShape: {df_clean.shape}\")\n",
    "# Optional: Save cleaned data\n",
    "# df_clean.to_csv('Product_Datasets_Cleaned.csv', index=False)\n",
    "# print(\"\\n✓ Cleaned data saved to 'Product_Datasets_Cleaned.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d8e275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Cleaned data saved to 'Product_Datasets_Cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "# save cleaned data\n",
    "df_clean.to_csv('Product_Datasets_Cleaned.csv', index=False)\n",
    "print(\"\\n✓ Cleaned data saved to 'Product_Datasets_Cleaned.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d204ec9",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "- sdfad\n",
    "- adfsdf\n",
    "\n",
    "---\n",
    "\n",
    "# Data Engineering / Pre-processing\n",
    "- Tokenization (splitting text into individual words/tokens)\n",
    "- Removal of Stop Words (common words like \"the,\" \"is,\" \"a\")\n",
    "- Stemming or Lemmatization (reducing words to their root form, e.g., \"processing\" $\\rightarrow$ \"process\")\n",
    "\n",
    "## Concatination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dae1f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TEXT_CONTENT column created\n"
     ]
    }
   ],
   "source": [
    "# initialize dataframe\n",
    "df_cleaned = pd.read_csv('Product_Datasets_Cleaned.csv')\n",
    "\n",
    "# Concatenate text columns into TEXT_CONTENT\n",
    "df_cleaned['TEXT_CONTENT'] = (\n",
    "    df_cleaned['PRODUCT TITLE'].fillna('').astype(str) + ' ' +\n",
    "    df_cleaned['PRODUCT DESCRIPTION'].fillna('').astype(str) + ' ' +\n",
    "    df_cleaned['COLOR'].fillna('').astype(str) + ' ' +\n",
    "    df_cleaned['SIZE'].fillna('').astype(str) + ' ' +\n",
    "    df_cleaned['MATERIAL'].fillna('').astype(str)\n",
    ")\n",
    "\n",
    "print(\"✓ TEXT_CONTENT column created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae913a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Text cleaning completed\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRODUCT TITLE</th>\n",
       "      <th>PRODUCT DESCRIPTION</th>\n",
       "      <th>COLOR</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>MATERIAL</th>\n",
       "      <th>TEXT_CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Halo-Halo Keychain</td>\n",
       "      <td>Miniature halo-halo dessert keychain made from...</td>\n",
       "      <td>Transparent, Multi-Colored</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>Clay, Resin</td>\n",
       "      <td>halo halo keychain miniature halo halo dessert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Filipino Funny Magnets</td>\n",
       "      <td>A set of novelty refrigerator magnets featurin...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>2 x 2 in</td>\n",
       "      <td>Vinyl-Coated Magnetic Sheet</td>\n",
       "      <td>filipino funny magnets a set of novelty refrig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Filipino Snacks Parody Stickers (Skyflakes, Su...</td>\n",
       "      <td>A set of Filipino parody snack stickers inspir...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>SUSMARYOSEP: 3.5 IN x 2 IN AND POTCHA: 3.25 IN...</td>\n",
       "      <td>Vinyl Sticker (Matte Finish)</td>\n",
       "      <td>filipino snacks parody stickers skyflakes susm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Philippine-Inspired Monogram Keychain</td>\n",
       "      <td>A 2-in tall handmade keychain featuring a mono...</td>\n",
       "      <td>Red, Blue, Yellow</td>\n",
       "      <td>2 IN</td>\n",
       "      <td>Resin, Sticker, Glitter, Metal Findings</td>\n",
       "      <td>philippine inspired monogram keychain a 2 in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Filipino Dessert Drink Stickers: Taho and Iskr...</td>\n",
       "      <td>A pair of illustrated stickers inspired by ico...</td>\n",
       "      <td>Multi-Colored</td>\n",
       "      <td>APPRO x . 3 IN x 2.3 IN</td>\n",
       "      <td>Vinyl Sticker (Matte Finish)</td>\n",
       "      <td>filipino dessert drink stickers taho and iskra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       PRODUCT TITLE  \\\n",
       "0                                 Halo-Halo Keychain   \n",
       "1                             Filipino Funny Magnets   \n",
       "2  Filipino Snacks Parody Stickers (Skyflakes, Su...   \n",
       "3              Philippine-Inspired Monogram Keychain   \n",
       "4  Filipino Dessert Drink Stickers: Taho and Iskr...   \n",
       "\n",
       "                                 PRODUCT DESCRIPTION  \\\n",
       "0  Miniature halo-halo dessert keychain made from...   \n",
       "1  A set of novelty refrigerator magnets featurin...   \n",
       "2  A set of Filipino parody snack stickers inspir...   \n",
       "3  A 2-in tall handmade keychain featuring a mono...   \n",
       "4  A pair of illustrated stickers inspired by ico...   \n",
       "\n",
       "                        COLOR  \\\n",
       "0  Transparent, Multi-Colored   \n",
       "1               Multi-Colored   \n",
       "2               Multi-Colored   \n",
       "3           Red, Blue, Yellow   \n",
       "4               Multi-Colored   \n",
       "\n",
       "                                                SIZE  \\\n",
       "0                                              SMALL   \n",
       "1                                           2 x 2 in   \n",
       "2  SUSMARYOSEP: 3.5 IN x 2 IN AND POTCHA: 3.25 IN...   \n",
       "3                                               2 IN   \n",
       "4                            APPRO x . 3 IN x 2.3 IN   \n",
       "\n",
       "                                  MATERIAL  \\\n",
       "0                              Clay, Resin   \n",
       "1              Vinyl-Coated Magnetic Sheet   \n",
       "2             Vinyl Sticker (Matte Finish)   \n",
       "3  Resin, Sticker, Glitter, Metal Findings   \n",
       "4             Vinyl Sticker (Matte Finish)   \n",
       "\n",
       "                                        TEXT_CONTENT  \n",
       "0  halo halo keychain miniature halo halo dessert...  \n",
       "1  filipino funny magnets a set of novelty refrig...  \n",
       "2  filipino snacks parody stickers skyflakes susm...  \n",
       "3  philippine inspired monogram keychain a 2 in t...  \n",
       "4  filipino dessert drink stickers taho and iskra...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Text Standardization & Noise Reduction\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean and standardize text for NLP processing\n",
    "    \"\"\"\n",
    "    # Handle NaN or non-string values\n",
    "    if pd.isna(text) or text == '':\n",
    "        return ''\n",
    "    \n",
    "    # Ensure text is string type\n",
    "    text = str(text)\n",
    "    \n",
    "    # A. Lowercasing\n",
    "    text = text.lower()\n",
    "    \n",
    "    # B. Remove HTML Tags/URLs (common in scraped descriptions)\n",
    "    text = re.sub(r'<.*?>|http\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # C. Remove Punctuation (keep letters, numbers, and space)\n",
    "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
    "    \n",
    "    # D. Remove Extra Whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the TEXT_CONTENT column\n",
    "df_cleaned['TEXT_CONTENT'] = df_cleaned['TEXT_CONTENT'].apply(clean_text)\n",
    "\n",
    "print(\"✓ Text cleaning completed\\n\")\n",
    "\n",
    "df_cleaned.to_csv('Product_Datasets_check.csv', index=False)\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f3ccfe",
   "metadata": {},
   "source": [
    "## Tokenization and Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b23323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to find 'punkt'...\n",
      "✅ Resource 'punkt' found. Please ensure you have restarted the kernel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\63920\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\63920\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Word Frequency Analysis for Custom Stopwords Selection\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "print(\"Attempting to find 'punkt'...\")\n",
    "try:\n",
    "    # This line checks if the resource is present in the standard search paths\n",
    "    nltk.find('tokenizers/punkt')\n",
    "    print(\"✅ Resource 'punkt' found. Please ensure you have restarted the kernel.\")\n",
    "except LookupError:\n",
    "    # If it still fails, run the download command again just in case\n",
    "    print(\"❌ Resource 'punkt' still not found. Downloading again...\")\n",
    "    nltk.download('punkt')\n",
    "\n",
    "# Rerun the code after this.\n",
    "# Get standard English stopwords\n",
    "standard_stopwords = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3307125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "WORD FREQUENCY ANALYSIS FOR CUSTOM STOPWORDS\n",
      "======================================================================\n",
      "\n",
      "[STEP 2] Tokenizing all text...\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\63920/nltk_data'\n    - 'c:\\\\Users\\\\63920\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\nltk_data'\n    - 'c:\\\\Users\\\\63920\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\63920\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\63920\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLookupError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     19\u001b[39m     tokens = [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m t.isalnum() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(t) > \u001b[32m1\u001b[39m]\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokens\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m df_cleaned[\u001b[33m'\u001b[39m\u001b[33mALL_TOKENS\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf_cleaned\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTEXT_CONTENT\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasic_tokenize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Flatten all tokens into single list\u001b[39;00m\n\u001b[32m     27\u001b[39m all_tokens = [token \u001b[38;5;28;01mfor\u001b[39;00m tokens \u001b[38;5;129;01min\u001b[39;00m df_cleaned[\u001b[33m'\u001b[39m\u001b[33mALL_TOKENS\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\63920\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:4935\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4800\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4801\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4802\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4807\u001b[39m     **kwargs,\n\u001b[32m   4808\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4809\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4810\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4811\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4926\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4927\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4928\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4929\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4930\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4931\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4932\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4933\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4934\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4935\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\63920\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\63920\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\63920\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\63920\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mbasic_tokenize\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[32m     15\u001b[39m text = text.lower()\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m tokens = \u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Remove punctuation and single characters\u001b[39;00m\n\u001b[32m     19\u001b[39m tokens = [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m t.isalnum() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(t) > \u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\63920\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:142\u001b[39m, in \u001b[36mword_tokenize\u001b[39m\u001b[34m(text, language, preserve_line)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mword_tokenize\u001b[39m(text, language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m, preserve_line=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    128\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[33;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[33;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m \u001b[33;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     sentences = [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    144\u001b[39m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer.tokenize(sent)\n\u001b[32m    145\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\63920\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:119\u001b[39m, in \u001b[36msent_tokenize\u001b[39m\u001b[34m(text, language)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msent_tokenize\u001b[39m(text, language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    110\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[33;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[33;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    117\u001b[39m \u001b[33;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     tokenizer = \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer.tokenize(text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\63920\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:105\u001b[39m, in \u001b[36m_get_punkt_tokenizer\u001b[39m\u001b[34m(language)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;129m@functools\u001b[39m.lru_cache\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_punkt_tokenizer\u001b[39m(language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     98\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[33;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03m    a lru cache for performance.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m \u001b[33;03m    :type language: str\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\63920\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1744\u001b[39m, in \u001b[36mPunktTokenizer.__init__\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1743\u001b[39m     PunktSentenceTokenizer.\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1744\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\63920\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1749\u001b[39m, in \u001b[36mPunktTokenizer.load_lang\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m   1746\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1747\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[32m-> \u001b[39m\u001b[32m1749\u001b[39m     lang_dir = \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1750\u001b[39m     \u001b[38;5;28mself\u001b[39m._params = load_punkt_params(lang_dir)\n\u001b[32m   1751\u001b[39m     \u001b[38;5;28mself\u001b[39m._lang = lang\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\63920\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\data.py:579\u001b[39m, in \u001b[36mfind\u001b[39m\u001b[34m(resource_name, paths)\u001b[39m\n\u001b[32m    577\u001b[39m sep = \u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m\n\u001b[32m    578\u001b[39m resource_not_found = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[31mLookupError\u001b[39m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\63920/nltk_data'\n    - 'c:\\\\Users\\\\63920\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\nltk_data'\n    - 'c:\\\\Users\\\\63920\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\63920\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\63920\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=\"*70)\n",
    "print(\"WORD FREQUENCY ANALYSIS FOR CUSTOM STOPWORDS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================\n",
    "# STEP 2: Tokenize All Text\n",
    "# ============================================================\n",
    "print(\"\\n[STEP 2] Tokenizing all text...\")\n",
    "\n",
    "def basic_tokenize(text):\n",
    "    \"\"\"Basic tokenization with lowercase conversion\"\"\"\n",
    "    if pd.isna(text) or text == '':\n",
    "        return []\n",
    "    \n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove punctuation and single characters\n",
    "    tokens = [t for t in tokens if t.isalnum() and len(t) > 1]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "\n",
    "df_cleaned['ALL_TOKENS'] = df_cleaned['TEXT_CONTENT'].apply(basic_tokenize)\n",
    "\n",
    "# Flatten all tokens into single list\n",
    "all_tokens = [token for tokens in df_cleaned['ALL_TOKENS'] for token in tokens]\n",
    "\n",
    "print(f\"✓ Total tokens extracted: {len(all_tokens)}\")\n",
    "print(f\"✓ Unique tokens: {len(set(all_tokens))}\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 3: Calculate Word Frequencies\n",
    "# ============================================================\n",
    "print(\"\\n[STEP 3] Calculating word frequencies...\")\n",
    "\n",
    "# Get frequency distribution\n",
    "word_freq = Counter(all_tokens)\n",
    "\n",
    "print(f\"✓ Word frequencies calculated\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 4: Separate Words by Stopword Status\n",
    "# ============================================================\n",
    "print(\"\\n[STEP 4] Categorizing words...\")\n",
    "\n",
    "# Words that are already stopwords\n",
    "stopword_freq = {word: count for word, count in word_freq.items() \n",
    "                 if word in standard_stopwords}\n",
    "\n",
    "# Words that are NOT stopwords (candidates for custom stopwords)\n",
    "non_stopword_freq = {word: count for word, count in word_freq.items() \n",
    "                     if word not in standard_stopwords}\n",
    "\n",
    "print(f\"✓ Standard stopwords found: {len(stopword_freq)}\")\n",
    "print(f\"✓ Non-stopwords found: {len(non_stopword_freq)}\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 5: Display Complete Frequency Tables\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPLETE WORD FREQUENCY ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create DataFrames for better display\n",
    "print(\"\\n📊 ALL WORDS (Sorted by Frequency)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "all_freq_df = pd.DataFrame(word_freq.most_common(), \n",
    "                           columns=['Word', 'Frequency'])\n",
    "all_freq_df['Is_Stopword'] = all_freq_df['Word'].apply(\n",
    "    lambda x: 'Yes' if x in standard_stopwords else 'No'\n",
    ")\n",
    "all_freq_df['Cumulative_Frequency'] = all_freq_df['Frequency'].cumsum()\n",
    "all_freq_df['Percentage'] = (all_freq_df['Frequency'] / len(all_tokens) * 100).round(2)\n",
    "\n",
    "print(all_freq_df.to_string(index=False))\n",
    "\n",
    "# ============================================================\n",
    "# STEP 6: Top Non-Stopwords (Candidates for Custom Stopwords)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🎯 TOP NON-STOPWORDS (Candidates for Custom Stopwords)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nThese are frequent words NOT in standard stopwords.\")\n",
    "print(\"Review these to decide which should be added to custom_stopwords:\\n\")\n",
    "\n",
    "non_stopword_df = pd.DataFrame(\n",
    "    [(word, count) for word, count in non_stopword_freq.items()],\n",
    "    columns=['Word', 'Frequency']\n",
    ").sort_values('Frequency', ascending=False).reset_index(drop=True)\n",
    "\n",
    "non_stopword_df['Percentage'] = (\n",
    "    non_stopword_df['Frequency'] / len(all_tokens) * 100\n",
    ").round(2)\n",
    "\n",
    "print(non_stopword_df.head(50).to_string(index=True))\n",
    "\n",
    "# ============================================================\n",
    "# STEP 7: Category-Based Analysis\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"📂 CATEGORY-BASED WORD ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Common categories to identify\n",
    "categories = {\n",
    "    'Product_Types': ['sticker', 'keychain', 'magnet', 'earring', 'pin', 'bag', 'pouch'],\n",
    "    'Materials': ['vinyl', 'resin', 'clay', 'metal', 'polymer', 'beads', 'foam'],\n",
    "    'Colors': ['red', 'blue', 'yellow', 'green', 'brown', 'black', 'white', 'multi', 'colored'],\n",
    "    'Sizes': ['inch', 'small', 'medium', 'large', 'tall', 'approx'],\n",
    "    'Descriptors': ['handmade', 'handcrafted', 'featuring', 'inspired', 'designed', 'set'],\n",
    "    'Filipino_Terms': ['filipino', 'philippine', 'pinoy', 'pinay', 'tagalog']\n",
    "}\n",
    "\n",
    "print(\"\\nWord frequency by category:\")\n",
    "for category, words in categories.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for word in words:\n",
    "        if word in word_freq:\n",
    "            print(f\"  {word:20s} : {word_freq[word]:3d}\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 8: Visualizations\n",
    "# ============================================================\n",
    "print(\"\\n[STEP 8] Creating visualizations...\")\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Top 30 Most Common Words (All)\n",
    "ax1 = axes[0, 0]\n",
    "top_30 = all_freq_df.head(30)\n",
    "colors = ['red' if x == 'Yes' else 'steelblue' for x in top_30['Is_Stopword']]\n",
    "ax1.barh(range(len(top_30)), top_30['Frequency'], color=colors)\n",
    "ax1.set_yticks(range(len(top_30)))\n",
    "ax1.set_yticklabels(top_30['Word'])\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_xlabel('Frequency')\n",
    "ax1.set_title('Top 30 Most Common Words\\n(Red = Standard Stopwords)', fontweight='bold')\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 2. Top 30 Non-Stopwords\n",
    "ax2 = axes[0, 1]\n",
    "top_30_non = non_stopword_df.head(30)\n",
    "ax2.barh(range(len(top_30_non)), top_30_non['Frequency'], color='green', alpha=0.7)\n",
    "ax2.set_yticks(range(len(top_30_non)))\n",
    "ax2.set_yticklabels(top_30_non['Word'])\n",
    "ax2.invert_yaxis()\n",
    "ax2.set_xlabel('Frequency')\n",
    "ax2.set_title('Top 30 Non-Stopwords\\n(Candidates for Custom Stopwords)', fontweight='bold')\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 3. Word Length Distribution\n",
    "ax3 = axes[1, 0]\n",
    "word_lengths = [len(word) for word in all_tokens]\n",
    "ax3.hist(word_lengths, bins=range(2, 20), color='purple', alpha=0.7, edgecolor='black')\n",
    "ax3.set_xlabel('Word Length')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.set_title('Distribution of Word Lengths', fontweight='bold')\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Cumulative Frequency (Pareto)\n",
    "ax4 = axes[1, 1]\n",
    "top_100 = all_freq_df.head(100)\n",
    "ax4.plot(range(len(top_100)), top_100['Cumulative_Frequency'], color='darkorange', linewidth=2)\n",
    "ax4.fill_between(range(len(top_100)), top_100['Cumulative_Frequency'], alpha=0.3, color='orange')\n",
    "ax4.set_xlabel('Word Rank')\n",
    "ax4.set_ylabel('Cumulative Frequency')\n",
    "ax4.set_title('Cumulative Frequency (Top 100 Words)', fontweight='bold')\n",
    "ax4.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('word_frequency_analysis.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Visualizations saved as 'word_frequency_analysis.png'\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 9: Save Frequency Tables to CSV\n",
    "# ============================================================\n",
    "print(\"\\n[STEP 9] Saving frequency tables...\")\n",
    "\n",
    "# Save complete frequency table\n",
    "all_freq_df.to_csv('all_word_frequencies.csv', index=False)\n",
    "print(\"✓ Saved: all_word_frequencies.csv\")\n",
    "\n",
    "# Save non-stopwords only\n",
    "non_stopword_df.to_csv('non_stopword_frequencies.csv', index=False)\n",
    "print(\"✓ Saved: non_stopword_frequencies.csv\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 10: Recommendations for Custom Stopwords\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"💡 RECOMMENDATIONS FOR CUSTOM STOPWORDS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Suggest words that appear very frequently but may not add semantic value\n",
    "high_freq_threshold = 10  # Words appearing more than 10 times\n",
    "suggested_custom_stopwords = []\n",
    "\n",
    "print(f\"\\nWords appearing more than {high_freq_threshold} times:\")\n",
    "print(\"(Consider adding these to custom_stopwords if they don't add semantic value)\\n\")\n",
    "\n",
    "for word, count in non_stopword_df.head(40).values:\n",
    "    if count > high_freq_threshold:\n",
    "        # Check if it's a generic descriptor\n",
    "        generic_words = ['featuring', 'inspired', 'designed', 'made', 'set', \n",
    "                        'inch', 'product', 'item', 'perfect', 'ideal', 'great']\n",
    "        status = \"⚠️  CONSIDER\" if word in generic_words else \"✓ KEEP\"\n",
    "        suggested_custom_stopwords.append((word, count, status))\n",
    "        print(f\"{status:12s} - {word:20s} (frequency: {count})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ WORD FREQUENCY ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTotal unique words: {len(word_freq)}\")\n",
    "print(f\"Total tokens processed: {len(all_tokens)}\")\n",
    "print(f\"\\nReview the CSV files and visualizations to decide on custom stopwords.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42eaba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\63920\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\63920\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\63920\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\63920\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Tokenization and Stopword Removal\n",
    "# Import required libraries\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# Download required NLTK resources (run once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Get English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d47e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "custom_stopwords = {\n",
    "    'product', 'item', 'featuring', 'made', 'designed', 'inspired',\n",
    "    'perfect', 'ideal', 'great', 'comes', 'includes'\n",
    "}\n",
    "stop_words.update(custom_stopwords)\n",
    "\n",
    "print(f\"Total stopwords: {len(stop_words)}\")\n",
    "print(f\"\\nSample stopwords: {list(stop_words)[:20]}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5059c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def tokenize_text(text):\n",
    "    \"\"\"\n",
    "    Tokenize text into individual words\n",
    "    \n",
    "    Args:\n",
    "        text: Input string to tokenize\n",
    "    \n",
    "    Returns:\n",
    "        List of tokens (words)\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text == '':\n",
    "        return []\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize using NLTK\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Apply tokenization\n",
    "df_cleaned['tokens'] = df_cleaned['combined_text'].apply(tokenize_text)\n",
    "\n",
    "# Display tokenization results\n",
    "print(\"\\nOriginal text:\")\n",
    "print(df_cleaned['combined_text'].iloc[0][:150])\n",
    "print(\"\\nTokenized:\")\n",
    "print(df_cleaned['tokens'].iloc[0][:30])\n",
    "print(f\"\\nTotal tokens in first product: {len(df_cleaned['tokens'].iloc[0])}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3166df",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def remove_stopwords_and_punctuation(tokens):\n",
    "    \"\"\"\n",
    "    Remove stopwords and punctuation from token list\n",
    "    \n",
    "    Args:\n",
    "        tokens: List of word tokens\n",
    "    \n",
    "    Returns:\n",
    "        Filtered list of tokens\n",
    "    \"\"\"\n",
    "    # Remove punctuation and stopwords\n",
    "    filtered_tokens = [\n",
    "        token for token in tokens \n",
    "        if token not in stop_words \n",
    "        and token not in string.punctuation\n",
    "        and len(token) > 1  # Remove single characters\n",
    "        and not token.isdigit()  # Remove pure numbers\n",
    "    ]\n",
    "    \n",
    "    return filtered_tokens\n",
    "\n",
    "# Apply stopword removal\n",
    "df_cleaned['tokens_filtered'] = df_cleaned['tokens'].apply(remove_stopwords_and_punctuation)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a5ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def lemmatize_tokens(tokens):\n",
    "    \"\"\"\n",
    "    Reduce tokens to their base/root form\n",
    "    \n",
    "    Args:\n",
    "        tokens: List of filtered tokens\n",
    "    \n",
    "    Returns:\n",
    "        List of lemmatized tokens\n",
    "    \"\"\"\n",
    "    lemmatized = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return lemmatized\n",
    "\n",
    "# Apply lemmatization\n",
    "df_cleaned['tokens_lemmatized'] = df_cleaned['tokens_filtered'].apply(lemmatize_tokens)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f61d44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_cleaned['processed_text'] = df_cleaned['tokens_lemmatized'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f55b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "''''\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 7: MOST COMMON TOKENS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Flatten all tokens into single list\n",
    "all_tokens = [token for tokens in df_cleaned['tokens_lemmatized'] for token in tokens]\n",
    "\n",
    "# Get most common tokens\n",
    "token_freq = Counter(all_tokens)\n",
    "most_common = token_freq.most_common(30)\n",
    "\n",
    "print(\"\\nTop 30 most common tokens:\")\n",
    "for token, count in most_common:\n",
    "    print(f\"{token:20s} : {count:3d}\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 8: Save Preprocessed Data\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 8: SAVING PREPROCESSED DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Select relevant columns for saving\n",
    "output_columns = [\n",
    "    'PRODUCT TITLE', 'PRODUCT DESCRIPTION', 'COLOR', 'SIZE', 'MATERIAL',\n",
    "    'processed_text', 'tokens_lemmatized'\n",
    "]\n",
    "\n",
    "# Save to CSV\n",
    "df_cleaned[output_columns].to_csv('Product_Datasets_Preprocessed.csv', index=False)\n",
    "print(\"\\n✓ Preprocessed data saved to 'Product_Datasets_Preprocessed.csv'\")\n",
    "\n",
    "# Display final dataframe info\n",
    "print(\"\\nFinal DataFrame shape:\", df_cleaned.shape)\n",
    "print(\"\\nColumns:\", df_cleaned.columns.tolist())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ TOKENIZATION AND STOPWORD REMOVAL COMPLETED!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
